{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d7d2d8",
   "metadata": {},
   "source": [
    "### Query Pinecone and Feast Stores\n",
    "In this notebook, we load the Pinecone embedding store with the values from Feast. Pinecone allows for similarity searching -- we can query the store with a new vector and return the stored vectors that are closest in distance. \n",
    "\n",
    "Feast can store both questions and answers; therefore, we can use the best matching vector to predict the answer to a question the user will ask. First, we follow the process using the [tutorial from Pinecone](https://www.pinecone.io/docs/examples/question-answering/) with a few modifications to the API. This uses a Quora question duplication dataset. \n",
    "\n",
    "We then change the underlying data and the models so that we can return answers. This is using Google's Natural Questions dataset and a model from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "528c9ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from feast import FeatureStore\n",
    "import pinecone\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2668cf36",
   "metadata": {},
   "source": [
    "#### Pinecone Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2cd5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb26ac3ddbd647ff84869b1630de7a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e231e3ba1a24a1c8c7062848a046ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f319bb897780494489b3e9eb53c28661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cc6d0328fb4b0fb1e695c2ef2cd234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/248 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b306406fb1400c93e791856e2e2136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/267M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ea74b16ab1440dbd5c6fc9842807b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.59M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b368dcb5baf43338e9da8257eec0c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/164 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b40343de884f728af41d50ca0d4d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initiate pinecone and load model object\n",
    "api_key = 'a1f44a5f-1978-4b1a-9a42-502b0a48d175'\n",
    "pinecone.init(api_key=api_key)\n",
    "pinecone.list_indexes()\n",
    "\n",
    "os.chdir('feature_repo')\n",
    "model = SentenceTransformer('average_word_embeddings_komninos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23a0a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new vector index\n",
    "index_name = 'feast-questions'\n",
    "\n",
    "if index_name in pinecone.list_indexes():\n",
    "    pinecone.delete_index(index_name)\n",
    "    \n",
    "pinecone.create_index(name=index_name, dimension=300, metric='cosine', shards=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e530b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the created index and load it with feast vectors\n",
    "# Set up\n",
    "question_ids = pd.read_parquet('./feature_repo/data/questions.parquet', columns=['qid1'])\n",
    "BATCH_SIZE = 450\n",
    "dimensions = 300\n",
    "store = FeatureStore(repo_path=\"./feature_repo/\")\n",
    "index = pinecone.Index('feast-questions')\n",
    "\n",
    "# Chunk upserts into the pinecone database\n",
    "for i in range(0, len(question_ids), BATCH_SIZE):\n",
    "    batch = question_ids[i: i+BATCH_SIZE]\n",
    "\n",
    "    feature_vectors = store.get_online_features(\n",
    "        features=[f'questions:e_{i}' for i in range(dimensions)],\n",
    "        entity_rows=[{\"qid1\":_id} for _id in batch.qid1.to_list()]\n",
    "    ).to_dict()\n",
    "\n",
    "    # Prepare list of items to upload into Pinecone's index\n",
    "    items_to_insert = []\n",
    "\n",
    "    for e in range(len(feature_vectors['qid1'])):\n",
    "        l = [feature_vectors[f'e_{i}'][e] for i in range(dimensions)]\n",
    "        items_to_insert.append((str(feature_vectors['qid1'][e]), l))\n",
    "        tuple_insert = tuple(items_to_insert)\n",
    "    \n",
    "    # Upsert batch data\n",
    "    index.upsert(vectors=tuple_insert)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "405be8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/01/2022 04:03:20 PM INFO:Load pretrained SentenceTransformer: average_word_embeddings_komninos\n",
      "04/01/2022 04:04:23 PM INFO:Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe for new questions\n",
    "df_new_questions = pd.DataFrame([[1000001, 'How can I make money using Youtube?'], \n",
    "                                 [1000002, 'What is the best book for learning Python?']], \n",
    "                                    columns=['qid1', 'question1'])\n",
    "\n",
    "# Create embedding for each question\n",
    "model = SentenceTransformer('average_word_embeddings_komninos')\n",
    "df_new_questions['question_vector'] = df_new_questions.question1.apply(lambda x: model.encode(str(x), show_progress_bar=False))\n",
    "\n",
    "# Create timestamps \n",
    "df_new_questions['created'] = datetime.datetime.utcnow()\n",
    "df_new_questions['datetime'] = df_new_questions['created'].dt.floor('h')\n",
    "\n",
    "# Generate columns for vector elements\n",
    "df_new_questions2 = df_new_questions.question_vector.apply(pd.Series)\n",
    "df_new_questions2.columns = [f'e_{i}' for i in range(300)]\n",
    "result = pd.concat([df_new_questions, df_new_questions2], axis=1)\n",
    "\n",
    "# Exclude some columns\n",
    "result = result.drop(['question_vector'], axis=1)\n",
    "\n",
    "# Change directory if needed\n",
    "if os.getcwd().split('/')[-1] != 'feature_repo':\n",
    "    os.chdir('feature_repo')\n",
    "\n",
    "# Save to parquet file\n",
    "result.to_parquet('./data/test_questions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64977d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the feature store and get feature vectors for the query questions\n",
    "store = FeatureStore(repo_path=\".\")\n",
    "\n",
    "feature_vectors = store.get_online_features(\n",
    "    features=[f'test_questions:question1',\n",
    "                  *[f'test_questions:e_{i}'\n",
    "                    for i in range(300)\n",
    "                  ]],\n",
    "    entity_rows=[{\"qid1\":_id} for _id in df_new_questions.qid1.tolist()]\n",
    ").to_dict()\n",
    "\n",
    "# Prepare list of vectors to query Pinecone\n",
    "query_vectors = []\n",
    "\n",
    "for e in range(len(feature_vectors['qid1'])):\n",
    "    l = [feature_vectors[f'e_{i}'][e] for i in range(300)]\n",
    "    query_vectors.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d9f87a28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Original question: How can I make money using Youtube?\n",
      "Most similar questions based on Pinecone vector search: \n"
     ]
    },
    {
     "ename": "EntityNotFoundException",
     "evalue": "Entity qid1 does not exist in project feature_repo",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/feast/feature_store.py\u001b[0m in \u001b[0;36m_get_online_features\u001b[0;34m(self, features, entity_values, full_feature_names, native_entity_values)\u001b[0m\n\u001b[1;32m   1318\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m                     \u001b[0mjoin_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentity_name_to_join_key_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentity_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'qid1'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEntityNotFoundException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3709/687054802.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     result_feature_vectors = store.get_online_features(\n\u001b[1;32m     15\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'questions:question1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mentity_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"qid1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     ).to_dict()\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/feast/usage.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/feast/usage.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/feast/feature_store.py\u001b[0m in \u001b[0;36mget_online_features\u001b[0;34m(self, features, entity_rows, full_feature_names)\u001b[0m\n\u001b[1;32m   1227\u001b[0m             \u001b[0mentity_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumnar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0mfull_feature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_feature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mnative_entity_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         )\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/feast/feature_store.py\u001b[0m in \u001b[0;36m_get_online_features\u001b[0;34m(self, features, entity_values, full_feature_names, native_entity_values)\u001b[0m\n\u001b[1;32m   1319\u001b[0m                     \u001b[0mjoin_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentity_name_to_join_key_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentity_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEntityNotFoundException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m                 \u001b[0;31m# All join keys should be returned in the result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m                 \u001b[0mrequested_result_row_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEntityNotFoundException\u001b[0m: Entity qid1 does not exist in project feature_repo"
     ]
    }
   ],
   "source": [
    "# Query Pinecone's index\n",
    "query_results = index.query(queries=query_vectors, top_k=5)\n",
    "\n",
    "# Show results\n",
    "for e, res in enumerate(query_results['results']):\n",
    "    print(e)\n",
    "    print('Original question: ' + feature_vectors['question1'][e])\n",
    "    print('Most similar questions based on Pinecone vector search: ')\n",
    "\n",
    "    # Fetch from Feast to get question text\n",
    "    ids = [d['id'] for d in res.matches]\n",
    "    scores = [d['score'] for d in res.matches]\n",
    "    \n",
    "    result_feature_vectors = store.get_online_features(\n",
    "        features=[f'questions:question1'],\n",
    "        entity_rows=[{\"qid1\":int(_id)} for _id in ids]\n",
    "    ).to_dict()\n",
    "\n",
    "    # Prepare and display table\n",
    "    df_result = pd.DataFrame({'id':ids,\n",
    "                              'question': result_feature_vectors['question1'],\n",
    "                              'score':scores})\n",
    "    display(df_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b9ba8838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qid1': [1292, 14375, 1126, 3759, 157],\n",
       " 'question1': ['How do I make money with YouTube?',\n",
       "  'How do I make money using Instagram?',\n",
       "  'How can I earn money from YouTube?',\n",
       "  'How do you make money giving through a app?',\n",
       "  'How can I make money through the Internet?']}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_feature_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1b65db",
   "metadata": {},
   "source": [
    "### Recreating with a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cb7b3771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete existing index as Pinecone only allows for 1\n",
    "old_index = 'feast-questions'\n",
    "pinecone.delete_index(old_index)\n",
    "\n",
    "# Create a new vector index\n",
    "index_name = 'nq-questions'\n",
    "dimensions = 384 \n",
    "\n",
    "if index_name in pinecone.list_indexes():\n",
    "    pinecone.delete_index(index_name)\n",
    "    \n",
    "pinecone.create_index(name=index_name, dimension=dimensions, metric='cosine', shards=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ef3892cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the created index and load it with feast vectors\n",
    "# Set up\n",
    "question_ids = pd.read_parquet('./data/NQ_questions.parquet', columns=['qid'])\n",
    "BATCH_SIZE = 450\n",
    "dimensions = 384\n",
    "store = FeatureStore(repo_path=\".\")\n",
    "index = pinecone.Index('nq-questions')\n",
    "\n",
    "# Chunk upserts into the pinecone database\n",
    "for i in range(0, len(question_ids), BATCH_SIZE):\n",
    "    batch = question_ids[i: i+BATCH_SIZE]\n",
    "\n",
    "    feature_vectors = store.get_online_features(\n",
    "        features=[f'questions:e_{i}' for i in range(dimensions)],\n",
    "        entity_rows=[{\"qid\":_id} for _id in batch.qid.to_list()]\n",
    "    ).to_dict()\n",
    "\n",
    "    # Prepare list of items to upload into Pinecone's index\n",
    "    items_to_insert = []\n",
    "\n",
    "    for e in range(len(feature_vectors['qid'])):\n",
    "        l = [feature_vectors[f'e_{i}'][e] for i in range(dimensions)]\n",
    "        items_to_insert.append((str(feature_vectors['qid'][e]), l))\n",
    "        tuple_insert = tuple(items_to_insert)\n",
    "    \n",
    "    # Upsert batch data\n",
    "    index.upsert(vectors=tuple_insert)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7332b0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/01/2022 10:40:21 PM INFO:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "04/01/2022 10:40:22 PM INFO:Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe for new questions\n",
    "df_new_questions = pd.DataFrame([[1000001, 'What is the capital of Pennsylvania?'], \n",
    "                                 [1000002, 'How nutritious are apples?']], \n",
    "                                    columns=['qid', 'question1'])\n",
    "\n",
    "# Create embedding for each question\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "df_new_questions['question_vector'] = df_new_questions.question1.apply(lambda x: model.encode(str(x), show_progress_bar=False))\n",
    "\n",
    "# Create timestamps \n",
    "df_new_questions['created'] = datetime.datetime.utcnow()\n",
    "df_new_questions['datetime'] = df_new_questions['created'].dt.floor('h')\n",
    "\n",
    "# Generate columns for vector elements\n",
    "df_new_questions2 = df_new_questions.question_vector.apply(pd.Series)\n",
    "df_new_questions2.columns = [f'e_{i}' for i in range(dimensions)]\n",
    "result = pd.concat([df_new_questions, df_new_questions2], axis=1)\n",
    "\n",
    "# Exclude some columns\n",
    "result = result.drop(['question_vector'], axis=1)\n",
    "\n",
    "# Change directory if needed\n",
    "if os.getcwd().split('/')[-1] != 'feature_repo':\n",
    "    os.chdir('feature_repo')\n",
    "\n",
    "# Save to parquet file\n",
    "result.to_parquet('./data/test_questions.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f0db0009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the feature store and get feature vectors for the query questions\n",
    "store = FeatureStore(repo_path=\".\")\n",
    "\n",
    "feature_vectors = store.get_online_features(\n",
    "    features=[f'test_questions:question1',\n",
    "                  *[f'test_questions:e_{i}'\n",
    "                    for i in range(dimensions)\n",
    "                  ]],\n",
    "    entity_rows=[{\"qid\":_id} for _id in df_new_questions.qid.tolist()]\n",
    ").to_dict()\n",
    "\n",
    "# Prepare list of vectors to query Pinecone\n",
    "query_vectors = []\n",
    "\n",
    "for e in range(len(feature_vectors['qid'])):\n",
    "    l = [feature_vectors[f'e_{i}'][e] for i in range(dimensions)]\n",
    "    query_vectors.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fb927e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Original question: What is the capital of Pennsylvania?\n",
      "Most similar questions based on Pinecone vector search: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6408</td>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Province_of_Pennsylvania&amp;amp;oldid=865431192</td>\n",
       "      <td>0.633106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2179</td>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Philadelphia&amp;amp;oldid=807750048</td>\n",
       "      <td>0.631774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9229</td>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Pennsylvania&amp;amp;oldid=866292516</td>\n",
       "      <td>0.589458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7379</td>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Pennsylvania_State_University&amp;amp;oldid=831460048</td>\n",
       "      <td>0.559006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6384</td>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=West_Virginia&amp;amp;oldid=835287674</td>\n",
       "      <td>0.540130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  \\\n",
       "0  6408   \n",
       "1  2179   \n",
       "2  9229   \n",
       "3  7379   \n",
       "4  6384   \n",
       "\n",
       "                                                                                        question  \\\n",
       "0       https://en.wikipedia.org//w/index.php?title=Province_of_Pennsylvania&amp;oldid=865431192   \n",
       "1                   https://en.wikipedia.org//w/index.php?title=Philadelphia&amp;oldid=807750048   \n",
       "2                   https://en.wikipedia.org//w/index.php?title=Pennsylvania&amp;oldid=866292516   \n",
       "3  https://en.wikipedia.org//w/index.php?title=Pennsylvania_State_University&amp;oldid=831460048   \n",
       "4                  https://en.wikipedia.org//w/index.php?title=West_Virginia&amp;oldid=835287674   \n",
       "\n",
       "      score  \n",
       "0  0.633106  \n",
       "1  0.631774  \n",
       "2  0.589458  \n",
       "3  0.559006  \n",
       "4  0.540130  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Original question: How nutritious are apples?\n",
      "Most similar questions based on Pinecone vector search: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6550</td>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=An_apple_a_day_keeps_the_doctor_away&amp;amp;oldid=829882694</td>\n",
       "      <td>0.535801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>531</td>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Apples_and_Bananas&amp;amp;oldid=795113537</td>\n",
       "      <td>0.512015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999</td>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=An_apple_a_day_keeps_the_doctor_away&amp;amp;oldid=805434402</td>\n",
       "      <td>0.467765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4380</td>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Golden_Apples_of_the_Sun&amp;amp;oldid=695291390</td>\n",
       "      <td>0.458660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2384</td>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Waterlogging_(agriculture)&amp;amp;oldid=791681328</td>\n",
       "      <td>0.441215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  \\\n",
       "0  6550   \n",
       "1   531   \n",
       "2   999   \n",
       "3  4380   \n",
       "4  2384   \n",
       "\n",
       "                                                                                               question  \\\n",
       "0  https://en.wikipedia.org//w/index.php?title=An_apple_a_day_keeps_the_doctor_away&amp;oldid=829882694   \n",
       "1                    https://en.wikipedia.org//w/index.php?title=Apples_and_Bananas&amp;oldid=795113537   \n",
       "2  https://en.wikipedia.org//w/index.php?title=An_apple_a_day_keeps_the_doctor_away&amp;oldid=805434402   \n",
       "3              https://en.wikipedia.org//w/index.php?title=Golden_Apples_of_the_Sun&amp;oldid=695291390   \n",
       "4            https://en.wikipedia.org//w/index.php?title=Waterlogging_(agriculture)&amp;oldid=791681328   \n",
       "\n",
       "      score  \n",
       "0  0.535801  \n",
       "1  0.512015  \n",
       "2  0.467765  \n",
       "3  0.458660  \n",
       "4  0.441215  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query Pinecone's index\n",
    "query_results = index.query(queries=query_vectors, top_k=5)\n",
    "\n",
    "# Show results\n",
    "for e, res in enumerate(query_results['results']):\n",
    "    print(e)\n",
    "    print('Original question: ' + feature_vectors['question1'][e])\n",
    "    print('Most similar questions based on Pinecone vector search: ')\n",
    "\n",
    "    # Fetch from Feast to get question text\n",
    "    ids = [d['id'] for d in res.matches]\n",
    "    scores = [d['score'] for d in res.matches]\n",
    "    \n",
    "    result_feature_vectors = store.get_online_features(\n",
    "        features=[f'questions:document_url'],\n",
    "        entity_rows=[{\"qid\":int(_id)} for _id in ids]\n",
    "    ).to_dict()\n",
    "\n",
    "    # Prepare and display table\n",
    "    df_result = pd.DataFrame({'id':ids,\n",
    "                              'question': result_feature_vectors['document_url'],\n",
    "                              'score':scores})\n",
    "    display(df_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
